{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c772252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<git.diff.Diff object at 0x0000025BB52AB130>, <git.diff.Diff object at 0x0000025BB52AB250>, <git.diff.Diff object at 0x0000025BB52AB2E0>]\n",
      "code_changes.csv\n",
      "\n",
      "palindrome.py\n",
      "\n",
      "run.py\n",
      "\n",
      "{'palindrome'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbulusu\\AppData\\Local\\Temp\\ipykernel_3188\\2460083103.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\"file\": file, \"lines_added\": lines_added, \"lines_removed\": lines_removed ,\"Code_Changes\": code_changes,'Method_Names':methods_list}, ignore_index=True)\n",
      "C:\\Users\\sbulusu\\AppData\\Local\\Temp\\ipykernel_3188\\2460083103.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\"file\": file, \"lines_added\": lines_added, \"lines_removed\": lines_removed ,\"Code_Changes\": code_changes,'Method_Names':methods_list}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import git\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from run1 import *\n",
    "from codeToMethodMapping import *\n",
    "\n",
    "def get_changed_methods(commit_hash):\n",
    "    # Use Git to get the diff of the current commit and its parent\n",
    "    diff = subprocess.check_output(['git', 'diff', '--name-only', commit_hash + '^', commit_hash])\n",
    "\n",
    "    # Split the diff output into individual file paths\n",
    "    file_paths = diff.decode().split('\\n')\n",
    "\n",
    "    # Filter the file paths to include only Python files\n",
    "    py_files = [path for path in file_paths if path.endswith('.py')]\n",
    "\n",
    "    changed_methods = set()\n",
    "\n",
    "    for py_file in py_files:\n",
    "        # Use Git to get the diff of the current file\n",
    "        file_diff = subprocess.check_output(['git', 'diff', commit_hash + '^', commit_hash, '--', py_file])\n",
    "\n",
    "        # Split the file diff into individual lines\n",
    "        file_diff_lines = file_diff.decode().split('\\n')\n",
    "        \n",
    "        # Find lines starting with either 'def ' or 'async def '\n",
    "        method_lines = [line.strip() for line in file_diff_lines if line.strip().startswith(\"def\") or line.strip().startswith('async def ')]\n",
    "\n",
    "        # Extract the method name from each line and add it to the set of changed methods\n",
    "        for line in method_lines:\n",
    "            method_name = line.split(' ')[1].split('(')[0]\n",
    "            changed_methods.add(method_name)\n",
    "\n",
    "    return changed_methods\n",
    "\n",
    "\n",
    "\n",
    "# Path to the Git repository\n",
    "repo_path = \"C:/Users/sbulusu/OneDrive - Informatica/Desktop/HackathonProject/hackathon/.git\"\n",
    "\n",
    "\n",
    "# Create a Git repository object\n",
    "repo = git.Repo(repo_path)\n",
    "\n",
    "# Get the main branch\n",
    "main_branch = repo.heads.main\n",
    "\n",
    "# Get the latest commit on the main branch\n",
    "latest_commit = main_branch.commit\n",
    "\n",
    "methods_list = get_changed_methods(str(latest_commit))\n",
    "print(methods_list)\n",
    "\n",
    "\n",
    "# Get the previous commit on the main branch\n",
    "previous_commit = latest_commit.parents[0]\n",
    "\n",
    "# Get the list of files changed between the previous and latest commits\n",
    "changed_files = repo.git.diff(\"--name-only\", previous_commit, latest_commit).split()\n",
    "\n",
    "\n",
    "# Initialize a pandas DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=[\"file\", \"lines_added\", \"lines_removed\" ,\"Code_Changes\", \"Method_Names\"])\n",
    "\n",
    "# Iterate over each changed file and extract the lines added and removed\n",
    "for file in changed_files:\n",
    "\n",
    "\n",
    "     # Skip non-Python files\n",
    "    if not file.endswith(\".py\"):\n",
    "        continue\n",
    "\n",
    "    # mapping = map_changes_to_methods(repo_path,file)\n",
    "    # print(mapping)\n",
    "\n",
    "     # Get the diff of the file between the previous and latest commits\n",
    "    diff_text = repo.git.diff(\"-U0\", previous_commit, latest_commit, file)\n",
    "\n",
    "    # Parse the diff text into a list of lines\n",
    "    diff_lines = diff_text.split(\"\\n\")\n",
    "\n",
    "    # Extract the lines added and removed\n",
    "    lines_added = 0\n",
    "    lines_removed = 0\n",
    "    code_changes = []\n",
    "    \n",
    "    for line in diff_lines:\n",
    "        if line.startswith(\"+\") and not line.startswith(\"+++\"):\n",
    "            lines_added += 1\n",
    "            code_changes.append(line)\n",
    "        elif line.startswith(\"-\") and not line.startswith(\"---\"):\n",
    "            lines_removed += 1\n",
    "            code_changes.append(line)\n",
    "        \n",
    "    # Add the file and lines added and removed to the DataFrame\n",
    "    results_df = results_df.append({\"file\": file, \"lines_added\": lines_added, \"lines_removed\": lines_removed ,\"Code_Changes\": code_changes,'Method_Names':methods_list}, ignore_index=True)\n",
    "\n",
    "# Export the results to a CSV file\n",
    "results_df.to_csv(\"code_changes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "483299f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbulusu\\AppData\\Local\\Temp\\ipykernel_18000\\2835509628.py:100: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\"file\": file, \"lines_added\": lines_added, \"lines_removed\": lines_removed ,\"Code_Changes\": code_changes,'Method_Names':methods_list}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 2.4000 - accuracy: 0.2500 - val_loss: 2.4000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3940 - accuracy: 0.2500 - val_loss: 2.4022 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3888 - accuracy: 0.2500 - val_loss: 2.4044 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.3841 - accuracy: 0.5000 - val_loss: 2.4065 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3792 - accuracy: 0.5000 - val_loss: 2.4087 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.3741 - accuracy: 0.5000 - val_loss: 2.4109 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.3688 - accuracy: 0.5000 - val_loss: 2.4132 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.3633 - accuracy: 0.5000 - val_loss: 2.4155 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.3575 - accuracy: 0.5000 - val_loss: 2.4179 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3515 - accuracy: 0.5000 - val_loss: 2.4204 - val_accuracy: 0.0000e+00\n",
      "[0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "0    {'multiply', 'subtract'}\n",
      "Name: Method_Names, dtype: object\n",
      "{\n",
      "'\n",
      "m\n",
      "u\n",
      "l\n",
      "t\n",
      "i\n",
      "p\n",
      "l\n",
      "y\n",
      "'\n",
      ",\n",
      " \n",
      "'\n",
      "s\n",
      "u\n",
      "b\n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "'\n",
      "}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 144\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m new_code_change\u001b[38;5;241m.\u001b[39mat[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m--> 144\u001b[0m new_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtexts_to_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_code_change\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m new_padded_sequence \u001b[38;5;241m=\u001b[39m pad_sequences(new_sequence, maxlen\u001b[38;5;241m=\u001b[39mmax_length, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    146\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(new_padded_sequence)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\text.py:357\u001b[0m, in \u001b[0;36mTokenizer.texts_to_sequences\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtexts_to_sequences\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts):\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;124;03m\"\"\"Transforms each text in texts to a sequence of integers.\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m    Only top `num_words-1` most frequent words will be taken into account.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m        A list of sequences.\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtexts_to_sequences_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\text.py:386\u001b[0m, in \u001b[0;36mTokenizer.texts_to_sequences_generator\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[43mtext_to_word_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m            \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyzer(text)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\text.py:74\u001b[0m, in \u001b[0;36mtext_to_word_sequence\u001b[1;34m(input_text, filters, lower, split)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Converts a text to a sequence of words (or tokens).\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03mDeprecated: `tf.keras.preprocessing.text.text_to_word_sequence` does not\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    A list of words (or tokens).\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[1;32m---> 74\u001b[0m     input_text \u001b[38;5;241m=\u001b[39m \u001b[43minput_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[0;32m     76\u001b[0m translate_dict \u001b[38;5;241m=\u001b[39m {c: split \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m filters}\n\u001b[0;32m     77\u001b[0m translate_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mmaketrans(translate_dict)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "import git\n",
    "import subprocess\n",
    "\n",
    "def get_changed_methods(commit_hash):\n",
    "    # Use Git to get the diff of the current commit and its parent\n",
    "    diff = subprocess.check_output(['git', 'diff', '--name-only', commit_hash + '^', commit_hash])\n",
    "\n",
    "    # Split the diff output into individual file paths\n",
    "    file_paths = diff.decode().split('\\n')\n",
    "\n",
    "    # Filter the file paths to include only Python files\n",
    "    py_files = [path for path in file_paths if path.endswith('.py')]\n",
    "\n",
    "    changed_methods = set()\n",
    "\n",
    "    for py_file in py_files:\n",
    "        # Use Git to get the diff of the current file\n",
    "        file_diff = subprocess.check_output(['git', 'diff', commit_hash + '^', commit_hash, '--', py_file])\n",
    "\n",
    "        # Split the file diff into individual lines\n",
    "        file_diff_lines = file_diff.decode().split('\\n')\n",
    "        \n",
    "        # Find lines starting with either 'def ' or 'async def '\n",
    "        method_lines = [line.strip() for line in file_diff_lines if line.strip().startswith(\"def\") or line.strip().startswith('async def ')]\n",
    "\n",
    "        # Extract the method name from each line and add it to the set of changed methods\n",
    "        for line in method_lines:\n",
    "            method_name = line.split(' ')[1].split('(')[0]\n",
    "            changed_methods.add(method_name)\n",
    "\n",
    "    return changed_methods\n",
    "\n",
    "\n",
    "\n",
    "# Path to the Git repository\n",
    "repo_path = \"C:/Users/sbulusu/OneDrive - Informatica/Desktop/HackathonProject/hackathon/.git\"\n",
    "\n",
    "\n",
    "# Create a Git repository object\n",
    "repo = git.Repo(repo_path)\n",
    "\n",
    "# Get the main branch\n",
    "main_branch = repo.heads.main\n",
    "\n",
    "# Get the latest commit on the main branch\n",
    "latest_commit = main_branch.commit\n",
    "\n",
    "methods_list = get_changed_methods(str(latest_commit))\n",
    "\n",
    "\n",
    "\n",
    "# Get the previous commit on the main branch\n",
    "previous_commit = latest_commit.parents[0]\n",
    "\n",
    "# Get the list of files changed between the previous and latest commits\n",
    "changed_files = repo.git.diff(\"--name-only\", previous_commit, latest_commit).split()\n",
    "\n",
    "\n",
    "# Initialize a pandas DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=[\"file\", \"lines_added\", \"lines_removed\" ,\"Code_Changes\", \"Method_Names\"])\n",
    "\n",
    "# Iterate over each changed file and extract the lines added and removed\n",
    "for file in changed_files:\n",
    "\n",
    "\n",
    "     # Skip non-Python files\n",
    "    if not file.endswith(\".py\"):\n",
    "        continue\n",
    "\n",
    "    # mapping = map_changes_to_methods(repo_path,file)\n",
    "    # print(mapping)\n",
    "\n",
    "     # Get the diff of the file between the previous and latest commits\n",
    "    diff_text = repo.git.diff(\"-U0\", previous_commit, latest_commit, file)\n",
    "\n",
    "    # Parse the diff text into a list of lines\n",
    "    diff_lines = diff_text.split(\"\\n\")\n",
    "\n",
    "    # Extract the lines added and removed\n",
    "    lines_added = 0\n",
    "    lines_removed = 0\n",
    "    code_changes = []\n",
    "    \n",
    "    for line in diff_lines:\n",
    "        if line.startswith(\"+\") and not line.startswith(\"+++\"):\n",
    "            lines_added += 1\n",
    "            code_changes.append(line)\n",
    "        elif line.startswith(\"-\") and not line.startswith(\"---\"):\n",
    "            lines_removed += 1\n",
    "            code_changes.append(line)\n",
    "        \n",
    "    # Add the file and lines added and removed to the DataFrame\n",
    "    results_df = results_df.append({\"file\": file, \"lines_added\": lines_added, \"lines_removed\": lines_removed ,\"Code_Changes\": code_changes,'Method_Names':methods_list}, ignore_index=True)\n",
    "\n",
    "# Export the results to a CSV file\n",
    "results_df.to_csv(\"code_changes_final_input.csv\", index=False)\n",
    "\n",
    "# load the data\n",
    "df = pd.read_csv('code_changes.csv')\n",
    "\n",
    "# encode the 'impacted_tests' column as integers\n",
    "le = LabelEncoder()\n",
    "df['Impacted_tests'] = le.fit_transform(df['Impacted_tests'])\n",
    "\n",
    "# tokenize the code changes\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df['Method_Names'])\n",
    "sequences = tokenizer.texts_to_sequences(df['Method_Names'])\n",
    "\n",
    "# pad the sequences to ensure consistent length\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# define the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=64, input_length=max_length),\n",
    "    LSTM(64),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(df['Impacted_tests'].nunique(), activation='softmax')\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(padded_sequences, df['Impacted_tests'], epochs=10, validation_split=0.6)\n",
    "\n",
    "print(history.history['accuracy'])\n",
    "# predict the test cases for a new code change\n",
    "# new_code_change = ['+    print(\"kireddy\")']\n",
    "df1 = pd.read_csv('code_changes_final_input.csv')\n",
    "\n",
    "new_code_change = list(df1[\"Method_Names\"])\n",
    "# print(new_code_change)\n",
    "# for i in new_code_change.at[0]:\n",
    "#     print(i)\n",
    "new_sequence = tokenizer.texts_to_sequences([new_code_change])\n",
    "new_padded_sequence = pad_sequences(new_sequence, maxlen=max_length, padding='post')\n",
    "pred = model.predict(new_padded_sequence)[0]\n",
    "pred_test = le.inverse_transform([np.argmax(pred)])\n",
    "print(\"Predicted impacted test case:\", pred_test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91d8593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
